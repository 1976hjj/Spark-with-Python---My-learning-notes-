{"cells":[{"cell_type":"code","source":["#Transformations are leazy\ndf_num_range = spark.range(100).toDF(\"nums\")"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["\n#Narrow Transformations\ndf_narrow = df_num_range.where(\"nums % 2 = 0\")\n#Dataframes are immutable\n#Actions\ndf_new.take(5)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#http://backtobazics.com/big-data/spark/apache-spark-flatmap-example/"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["#Wide Transformations (shffes)\ndf_wide = df_num_range.where(\"nums % 2 = 0\").count()\nprint df_wide"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["df_ctry_summary = spark.read.csv(\"/FileStore/tables/ctry_summary.csv\")\ndf_ctry_summary.printSchema()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#get data schema from file \n#and ignore header\ndf_ctry_summary = spark.read.option(\"inferSchema\", \"true\").option(\"header\",\"true\").csv(\"/FileStore/tables/ctry_summary.csv\")\ndf_ctry_summary.printSchema()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#Explain plans are a bit arcane\ndf_grp_ctry = df_ctry_summary.sort(\"count\").explain()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# shuffle Spark will output two hundred shuffle partitions\n\nspark.conf.set(\"spark.sql.shuffel.partitions\", \"5\")\ndf_grp_ctry = df_ctry_summary.sort(\"count\").explain()"],"metadata":{},"outputs":[],"execution_count":9}],"metadata":{"name":"01012018_1","notebookId":3023601934734119},"nbformat":4,"nbformat_minor":0}
