{"cells":[{"cell_type":"code","source":["socketDF = spark \\\n    .readStream \\\n    .format(\"socket\") \\\n    .option(\"host\", \"localhost\") \\\n    .option(\"port\", 9999) \\\n    .load()"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["socketDF.isStreaming\ntmpSchema = socketDF.schema\ntmpSchema "],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["csvDF = spark.readStream\\\n.option(\"sep\", \" \")\\\n.schema(tmpSchema )\\\n.csv(\"/FileStore/tables/\")"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark.sql.functions import explode, split\nwords = csvDF.select(explode(split(csvDF.value, \" \")).alias(\"word\"))"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["wordCounts = words.groupBy(\"word\").count()\nprint wordCounts"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#wordCounts.writeStream\\\n#.outputMode(\"complete\")\\\n#.format(\"console\")\\\n#.start()\nrunningStream = wordCounts.writeStream\\\n.format(\"memory\")\\\n.queryName(\"myResult\")\\\n.outputMode(\"complete\")\\\n.start()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["dfRes = spark.sql(\"select * from myResult\")"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["dfRes.write.format(\"com.databricks.spark.csv\").save(\"/FileStore/tables/result.csv\")"],"metadata":{},"outputs":[],"execution_count":8}],"metadata":{"name":"sparkStreaming_basic_1","notebookId":863376660785188},"nbformat":4,"nbformat_minor":0}
